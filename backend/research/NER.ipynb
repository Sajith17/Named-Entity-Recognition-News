{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ttn6tUvB6rWv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
              " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.config.list_physical_devices()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.9.1'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3Nwyqvkp8Em",
        "outputId": "ad9dbd12-11c5-4ab9-a24e-cb0094b881cb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found cached dataset conll2003 (C:/Users/sajit/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98)\n",
            "100%|██████████| 3/3 [00:00<00:00, 120.09it/s]\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "data = load_dataset('conll2003')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJdsCF4-GL4e",
        "outputId": "3a5f5950-a5c6-4fc0-e406-4d3c5ffa1f56"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 14041\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 3250\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 3453\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gx84KbdOCAT",
        "outputId": "9ed0163d-37cd-4808-d1ca-8da654f4b790"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "17680"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "oov_token = '[UNK]'\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token=oov_token, lower=True)\n",
        "tokenizer.fit_on_texts([' '.join(x) for x in data['train']['tokens']])\n",
        "len(tokenizer.word_index)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "pMBIPQa5DlZB"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_align_labels(examples, label_all_tokens=True):\n",
        "  tokenized_inputs = [tokenizer.texts_to_sequences(token) for token in examples['tokens']]\n",
        "  new_tokenized_inputs = []\n",
        "  labels = []\n",
        "  word_ids_list = []\n",
        "  for i,tokenized_input in enumerate(tokenized_inputs):\n",
        "    ner_tags = examples['ner_tags'][i]\n",
        "    label_ids = []\n",
        "    word_ids = []\n",
        "    tokenized_sentence = []\n",
        "    for j,tokenized_words in enumerate(tokenized_input):\n",
        "      if tokenized_words:\n",
        "        tokenized_sentence.extend(tokenized_words)\n",
        "        word_ids.extend([j]*len(tokenized_words))\n",
        "        label_ids.append(ner_tags[j]+1)\n",
        "        for k in range(len(tokenized_words)-1):\n",
        "          label_ids.append(ner_tags[j]+1 if label_all_tokens else 0)\n",
        "    labels.append(label_ids)\n",
        "    word_ids_list.append(word_ids)\n",
        "    new_tokenized_inputs.append(tokenized_sentence)\n",
        "  return {'input_ids': new_tokenized_inputs, 'word_ids': word_ids_list, 'labels': labels}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "iikUQXd3793B"
      },
      "outputs": [],
      "source": [
        "def input_and_label_pad_sequence(examples, maxlen=100):\n",
        "  return { 'input_ids': tf.keras.preprocessing.sequence.pad_sequences(examples['input_ids'],maxlen = maxlen, padding='post', truncating='post'),\n",
        "           'labels': tf.keras.preprocessing.sequence.pad_sequences(examples['labels'],maxlen = maxlen, padding='post', truncating='post' )}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_padding_mask(examples):\n",
        "    seq = 1 - tf.cast(tf.math.equal(examples['input_ids'], 0), tf.int32)\n",
        "    return {\"attention_mask\": seq}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "NDjTmgH_LH3D"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at C:\\Users\\sajit\\.cache\\huggingface\\datasets\\conll2003\\conll2003\\1.0.0\\9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98\\cache-c04bed9a42356567.arrow\n",
            "Loading cached processed dataset at C:\\Users\\sajit\\.cache\\huggingface\\datasets\\conll2003\\conll2003\\1.0.0\\9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98\\cache-f0840bc6d022c9de.arrow\n",
            "Loading cached processed dataset at C:\\Users\\sajit\\.cache\\huggingface\\datasets\\conll2003\\conll2003\\1.0.0\\9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98\\cache-5c59ad2a74d550d1.arrow\n",
            "Loading cached processed dataset at C:\\Users\\sajit\\.cache\\huggingface\\datasets\\conll2003\\conll2003\\1.0.0\\9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98\\cache-2cedf137c4bc3781.arrow\n",
            "Loading cached processed dataset at C:\\Users\\sajit\\.cache\\huggingface\\datasets\\conll2003\\conll2003\\1.0.0\\9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98\\cache-307a6bcf631f76a9.arrow\n",
            "Loading cached processed dataset at C:\\Users\\sajit\\.cache\\huggingface\\datasets\\conll2003\\conll2003\\1.0.0\\9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98\\cache-611e980ee28907b1.arrow\n",
            "                                                                    \r"
          ]
        }
      ],
      "source": [
        "maxlen = 100\n",
        "\n",
        "data = data.map(tokenize_and_align_labels, batched=True).map(input_and_label_pad_sequence, batched=True).map(create_padding_mask, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Attempt to convert a value ({'id': '0', 'tokens': ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.'], 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7], 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0], 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0], 'input_ids': [946, 10365, 206, 633, 5, 3951, 216, 5739, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'word_ids': [0, 1, 2, 3, 4, 5, 6, 7], 'labels': [4, 1, 8, 1, 1, 1, 8, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}) with an unsupported type (<class 'dict'>) to a Tensor.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\data\\util\\structure.py\u001b[0m in \u001b[0;36mnormalize_element\u001b[1;34m(element, element_signature)\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m           \u001b[0mspec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_spec_from_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_fallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\data\\util\\structure.py\u001b[0m in \u001b[0;36mtype_spec_from_value\u001b[1;34m(element, use_fallback)\u001b[0m\n\u001b[0;32m    486\u001b[0m       \u001b[0melement\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m       type(element).__name__))\n\u001b[0m\u001b[0;32m    488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mTypeError\u001b[0m: Could not build a `TypeSpec` for Dataset({\n    features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags', 'input_ids', 'word_ids', 'labels', 'attention_mask'],\n    num_rows: 14041\n}) with type Dataset",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_41196\\882019909.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mexamples\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'input_ids'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mexamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'attention_mask'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mexamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'labels'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensor_slices\u001b[1;34m(tensors, name)\u001b[0m\n\u001b[0;32m    807\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    808\u001b[0m     \"\"\"\n\u001b[1;32m--> 809\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mTensorSliceDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m   \u001b[1;32mclass\u001b[0m \u001b[0m_GeneratorState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, element, is_files, name)\u001b[0m\n\u001b[0;32m   4549\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_files\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4550\u001b[0m     \u001b[1;34m\"\"\"See `Dataset.from_tensor_slices()` for details.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4551\u001b[1;33m     \u001b[0melement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4552\u001b[0m     \u001b[0mbatched_spec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4553\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_batched_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatched_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\data\\util\\structure.py\u001b[0m in \u001b[0;36mnormalize_element\u001b[1;34m(element, element_signature)\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[1;31m# the value. As a fallback try converting the value to a tensor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         normalized_components.append(\n\u001b[1;32m--> 107\u001b[1;33m             ops.convert_to_tensor(t, name=\"component_%d\" % i))\n\u001b[0m\u001b[0;32m    108\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensorSpec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\profiler\\trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1639\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1640\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1642\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    341\u001b[0m                                          as_ref=False):\n\u001b[0;32m    342\u001b[0m   \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    266\u001b[0m   \"\"\"\n\u001b[0;32m    267\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[1;32m--> 268\u001b[1;33m                         allow_broadcast=True)\n\u001b[0m\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    277\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tf.constant\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m   \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m   \u001b[1;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m   \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: Attempt to convert a value ({'id': '0', 'tokens': ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.'], 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7], 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0], 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0], 'input_ids': [946, 10365, 206, 633, 5, 3951, 216, 5739, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'word_ids': [0, 1, 2, 3, 4, 5, 6, 7], 'labels': [4, 1, 8, 1, 1, 1, 8, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}) with an unsupported type (<class 'dict'>) to a Tensor."
          ]
        }
      ],
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((data['train']['input_ids'],data['train']['attention_mask'],data['train']['labels'])).map(lambda x,y,z: ((x,y),z)).shuffle(10000).batch(64)\n",
        "test = tf.data.Dataset.from_tensor_slices((data['test']['input_ids'],data['test']['attention_mask'],data['test']['labels'])).map(lambda x,y,z: ((x,y),z))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: shape=(64, 200), dtype=int32, numpy=\n",
            "array([[ 3286,    14,  3287, ...,     0,     0,     0],\n",
            "       [    4,  9291,   218, ...,     0,     0,     0],\n",
            "       [   40,   107,   255, ...,     0,     0,     0],\n",
            "       ...,\n",
            "       [   27,    19,  1608, ...,     0,     0,     0],\n",
            "       [   23,  3527, 11665, ...,     0,     0,     0],\n",
            "       [ 1685,  3077,   144, ...,     0,     0,     0]])>, <tf.Tensor: shape=(64, 100), dtype=int32, numpy=\n",
            "array([[4, 1, 4, ..., 0, 0, 0],\n",
            "       [1, 6, 1, ..., 0, 0, 0],\n",
            "       [1, 8, 9, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 2, 3, ..., 0, 0, 0],\n",
            "       [2, 3, 6, ..., 0, 0, 0]])>)\n",
            "(<tf.Tensor: shape=(64, 200), dtype=int32, numpy=\n",
            "array([[ 145,   19,  687, ...,    0,    0,    0],\n",
            "       [   2,  602,   34, ...,    0,    0,    0],\n",
            "       [2787,   20,   21, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [2631,  274, 1263, ...,    0,    0,    0],\n",
            "       [ 610,   93,    0, ...,    0,    0,    0],\n",
            "       [ 292, 3429,   30, ...,    0,    0,    0]])>, <tf.Tensor: shape=(64, 100), dtype=int32, numpy=\n",
            "array([[1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [6, 1, 1, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [8, 9, 0, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0]])>)\n",
            "(<tf.Tensor: shape=(64, 200), dtype=int32, numpy=\n",
            "array([[2323, 1316,   48, ...,    0,    0,    0],\n",
            "       [2777,  912, 4248, ...,    0,    0,    0],\n",
            "       [1746,    3, 2354, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [8855,   18, 8856, ...,    0,    0,    0],\n",
            "       [  25,   51, 1288, ...,    0,    0,    0],\n",
            "       [  11, 4716, 4717, ...,    0,    0,    0]])>, <tf.Tensor: shape=(64, 100), dtype=int32, numpy=\n",
            "array([[1, 2, 1, ..., 0, 0, 0],\n",
            "       [2, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 8, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [4, 1, 4, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 2, 3, ..., 0, 0, 0]])>)\n"
          ]
        }
      ],
      "source": [
        "for x in dataset.take(3):\n",
        "    print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "eOy8izYqdpGD"
      },
      "outputs": [],
      "source": [
        "# @tf.keras.utils.register_keras_serializable()\n",
        "def positional_encoding(positions, d_model):\n",
        "\n",
        "    position = np.arange(positions)[:, np.newaxis]\n",
        "    k = np.arange(d_model)[np.newaxis, :]\n",
        "    i = k // 2\n",
        "\n",
        "    # initialize a matrix angle_rads of all the angles\n",
        "    angle_rates = 1 / np.power(10000, (2 * i) / np.float32(d_model))\n",
        "    angle_rads = position * angle_rates\n",
        "\n",
        "    # apply sin to even indices in the array; 2i\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "    # apply cos to odd indices in the array; 2i+1\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "07gEyi_3dt7N"
      },
      "outputs": [],
      "source": [
        "# @tf.keras.utils.register_keras_serializable()\n",
        "def create_padding_mask(decoder_token_ids):\n",
        "\n",
        "    seq = 1 - tf.cast(tf.math.equal(decoder_token_ids, 0), tf.float32)\n",
        "    return seq[:, tf.newaxis, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "90S6GyqBd90_"
      },
      "outputs": [],
      "source": [
        "# @tf.keras.utils.register_keras_serializable()\n",
        "def FullyConnected(embedding_dim, fully_connected_dim):\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(fully_connected_dim, activation='relu'),\n",
        "      tf.keras.layers.Dense(embedding_dim)\n",
        "  ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "lNTAEMtKes7K"
      },
      "outputs": [],
      "source": [
        "# @tf.keras.utils.register_keras_serializable()\n",
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, embedding_dim, num_heads, fully_connected_dim,\n",
        "               dropout_rate=0.1, layernorm_eps=1e-6):\n",
        "\n",
        "    super(EncoderLayer, self).__init__()\n",
        "\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=embedding_dim,\n",
        "        dropout=dropout_rate\n",
        "    )\n",
        "\n",
        "    self.ffn = FullyConnected(\n",
        "        embedding_dim=embedding_dim,\n",
        "        fully_connected_dim=fully_connected_dim\n",
        "    )\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=layernorm_eps)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=layernorm_eps)\n",
        "\n",
        "    self.dropout_ffn = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    self_mha_output = self.mha(x,x,x,mask)\n",
        "    skip_x_attention = self.layernorm1(x+self_mha_output)\n",
        "    ffn_output = self.ffn(skip_x_attention)\n",
        "    ffn_output = self.dropout_ffn(ffn_output, training=training)\n",
        "    encoder_layer_out = self.layernorm2(skip_x_attention+ffn_output)\n",
        "\n",
        "    return encoder_layer_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "U4wLAtb2gpzq"
      },
      "outputs": [],
      "source": [
        "# @tf.keras.utils.register_keras_serializable()\n",
        "class Encoder(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, num_layers, embedding_dim, num_heads, fully_connected_dim, vocab_size,\n",
        "               maximum_position_encoding, dropout_rate=0.1, layernorm_eps=1e-6):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.embedding_dim = embedding_dim\n",
        "\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding,\n",
        "                                            self.embedding_dim)\n",
        "\n",
        "    self.enc_layers = [EncoderLayer(embedding_dim=embedding_dim,\n",
        "                                    num_heads=num_heads,\n",
        "                                    fully_connected_dim=fully_connected_dim,\n",
        "                                    dropout_rate=dropout_rate,\n",
        "                                    layernorm_eps=layernorm_eps\n",
        "                                    )\n",
        "                      for _ in range(num_layers)]\n",
        "\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "     seq_len = tf.shape(x)[1]\n",
        "\n",
        "     x = self.embedding(x)\n",
        "\n",
        "     x*=tf.math.sqrt(tf.cast(self.embedding_dim, tf.float32))\n",
        "\n",
        "     x+=self.pos_encoding[:,:seq_len,:]\n",
        "\n",
        "     x = self.dropout(x, training=training)\n",
        "\n",
        "     for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x, training, mask)\n",
        "\n",
        "     return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "rpr8oO_-kdGb"
      },
      "outputs": [],
      "source": [
        "# @tf.keras.utils.register_keras_serializable()\n",
        "class NERModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, num_tags, num_layers, embedding_dim, num_heads, fully_connected_dim,\n",
        "               vocab_size, max_positional_encoding,dropout_rate=0.1,\n",
        "               layernorm_eps=1e-6):\n",
        "\n",
        "    super(NERModel, self).__init__()\n",
        "\n",
        "    self.encoder = Encoder(     num_layers=num_layers,\n",
        "                                embedding_dim=embedding_dim,\n",
        "                                num_heads=num_heads,\n",
        "                                fully_connected_dim=fully_connected_dim,\n",
        "                                vocab_size=vocab_size,\n",
        "                                maximum_position_encoding=max_positional_encoding,\n",
        "                                dropout_rate=dropout_rate,\n",
        "                                layernorm_eps=layernorm_eps)\n",
        "    self.create_padding_mask = create_padding_mask\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate=dropout_rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate=dropout_rate)\n",
        "    self.ffn = tf.keras.layers.Dense(fully_connected_dim, activation='relu')\n",
        "    self.ffn_final = tf.keras.layers.Dense(num_tags,activation='softmax')\n",
        "\n",
        "  def call(self, x, training):\n",
        "    x, mask = x\n",
        "    mask = mask[:,tf.newaxis,:]\n",
        "    x = self.encoder(x,training, mask)\n",
        "    x = self.dropout1(x, training = training)\n",
        "    x = self.ffn(x)\n",
        "    x = self.dropout2(x, training=training)\n",
        "    x = self.ffn_final(x)\n",
        "    return x\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHGwxs2SBOhi",
        "outputId": "e9b2404a-8010-4650-ab2f-96cb75ea57c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['train'].features['ner_tags']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "JTRHG0ALqQzM"
      },
      "outputs": [],
      "source": [
        "num_layers = 2\n",
        "num_tags = 10\n",
        "vocab_size = len(tokenizer.word_index)+1\n",
        "embedding_dim = 100\n",
        "fully_connected_dim = 100\n",
        "num_heads = 3\n",
        "positional_encoding_length = 150\n",
        "\n",
        "transformer = NERModel(\n",
        "    num_tags,\n",
        "    num_layers,\n",
        "    embedding_dim,\n",
        "    num_heads,\n",
        "    fully_connected_dim,\n",
        "    vocab_size,\n",
        "    positional_encoding_length,\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "DWaiNh7sJQ2v"
      },
      "outputs": [],
      "source": [
        "class CustomNonPaddingTokenLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self, name=\"custom_ner_loss\"):\n",
        "        super().__init__(name=name)\n",
        "        self.loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False, reduction='none')\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        mask = tf.math.logical_not(tf.math.equal(y_true, 0))\n",
        "        loss_ = self.loss_object(y_true, y_pred)\n",
        "\n",
        "        mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "        loss_ *= mask\n",
        "\n",
        "        return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "8WsUjdM7zxk2"
      },
      "outputs": [],
      "source": [
        "def acc(y_true, y_pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(y_true, 0))\n",
        "    mask = tf.cast(mask,dtype=tf.float32)\n",
        "    pred = tf.cast(tf.argmax(y_pred,axis=-1),dtype=tf.float32)\n",
        "    correct = tf.cast(tf.equal(y_true,pred),dtype=tf.float32)\n",
        "    correct*=mask\n",
        "    return tf.reduce_sum(correct)/tf.reduce_sum(mask)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Cum0pT6pDfvx"
      },
      "outputs": [],
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "        self.d_model = tf.cast(d_model, dtype=tf.float32)\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        step = tf.cast(step, dtype=tf.float32)\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
        "\n",
        "learning_rate = CustomSchedule(embedding_dim)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "PfV439uZLU_L"
      },
      "outputs": [],
      "source": [
        "transformer.compile(optimizer=optimizer, loss=[CustomNonPaddingTokenLoss()], metrics = [acc])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_41196\\808110156.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m transformer.fit(dataset,\n\u001b[1;32m----> 2\u001b[1;33m                 epochs = 1)\n\u001b[0m",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1370\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1371\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1372\u001b[1;33m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[0;32m   1373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1374\u001b[0m       \u001b[1;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1399\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_cluster_coordinator\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1400\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1401\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[0;32m   1166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1167\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_current_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1168\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step_increment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1169\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    635\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 637\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    638\u001b[0m     raise NotImplementedError(\n\u001b[0;32m    639\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1157\u001b[0m     \"\"\"\n\u001b[0;32m   1158\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1159\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1160\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1123\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1125\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1126\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "transformer.fit(dataset,\n",
        "                epochs = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "y4iQHJFiLf4f",
        "outputId": "fc9d657d-90ad-4db2-8aa4-34fb3dba2021"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "439/439 [==============================] - 10s 20ms/step - loss: 0.6173 - acc: 0.8375 - val_loss: 0.3979 - val_acc: 0.8832\n",
            "Epoch 2/10\n",
            "439/439 [==============================] - 9s 19ms/step - loss: 0.3000 - acc: 0.9122 - val_loss: 0.2944 - val_acc: 0.9089\n",
            "Epoch 3/10\n",
            "439/439 [==============================] - 8s 19ms/step - loss: 0.1908 - acc: 0.9437 - val_loss: 0.2673 - val_acc: 0.9198\n",
            "Epoch 4/10\n",
            "439/439 [==============================] - 8s 19ms/step - loss: 0.1336 - acc: 0.9600 - val_loss: 0.2809 - val_acc: 0.9200\n",
            "Epoch 5/10\n",
            "439/439 [==============================] - 8s 19ms/step - loss: 0.1037 - acc: 0.9681 - val_loss: 0.2557 - val_acc: 0.9260\n",
            "Epoch 6/10\n",
            "439/439 [==============================] - 8s 19ms/step - loss: 0.0842 - acc: 0.9738 - val_loss: 0.2724 - val_acc: 0.9215\n",
            "Epoch 7/10\n",
            "439/439 [==============================] - 8s 18ms/step - loss: 0.0722 - acc: 0.9772 - val_loss: 0.2609 - val_acc: 0.9355\n",
            "Epoch 8/10\n",
            "439/439 [==============================] - 8s 18ms/step - loss: 0.0650 - acc: 0.9791 - val_loss: 0.2717 - val_acc: 0.9305\n",
            "Epoch 9/10\n",
            "439/439 [==============================] - 8s 18ms/step - loss: 0.0569 - acc: 0.9819 - val_loss: 0.2385 - val_acc: 0.9393\n",
            "Epoch 10/10\n",
            "439/439 [==============================] - 8s 18ms/step - loss: 0.0474 - acc: 0.9847 - val_loss: 0.2613 - val_acc: 0.9348\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x2cc563725c8>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformer.fit(np.array(data['train']['input_ids']),np.array(data['train']['labels']),\n",
        "                validation_data = (np.array(data['validation']['input_ids']),np.array(data['validation']['labels'])),\n",
        "                epochs = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmRyRe3rQ8l1",
        "outputId": "886225f0-8859-4103-b342-bd5ba9705dbe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['It',\n",
              "  'was',\n",
              "  'the',\n",
              "  'second',\n",
              "  'costly',\n",
              "  'blunder',\n",
              "  'by',\n",
              "  'Syria',\n",
              "  'in',\n",
              "  'four',\n",
              "  'minutes',\n",
              "  '.'],\n",
              " [0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0],\n",
              " [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
              " [1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1])"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example = data['test'][11]\n",
        "example['tokens'],example['ner_tags'],example['word_ids'],example['labels'][:len(example['word_ids'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "54/54 [==============================] - 1s 11ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[[8.37833388e-04, 9.22988534e-01, 1.99593697e-02, ...,\n",
              "         3.94196343e-03, 7.31733255e-03, 2.78275367e-03],\n",
              "        [5.36015676e-03, 5.47678359e-02, 1.30722553e-01, ...,\n",
              "         2.70101726e-02, 1.22728571e-01, 1.05833998e-02],\n",
              "        [1.02137588e-03, 9.32893574e-01, 1.73388943e-02, ...,\n",
              "         1.54023687e-03, 2.87428312e-03, 1.71657803e-03],\n",
              "        ...,\n",
              "        [4.85457107e-03, 2.46248335e-01, 4.60228622e-02, ...,\n",
              "         2.92257909e-02, 3.42960320e-02, 1.92829035e-02],\n",
              "        [4.28594509e-03, 2.46103957e-01, 5.73346429e-02, ...,\n",
              "         4.14798558e-02, 4.62210290e-02, 2.35845707e-02],\n",
              "        [3.46482103e-03, 2.04038277e-01, 6.56586364e-02, ...,\n",
              "         4.79328707e-02, 5.56591153e-02, 2.11000573e-02]],\n",
              "\n",
              "       [[1.29649590e-03, 5.94195127e-01, 5.91423027e-02, ...,\n",
              "         9.45031643e-03, 3.33197340e-02, 9.30159818e-03],\n",
              "        [1.22464180e-03, 6.68993115e-01, 4.87397276e-02, ...,\n",
              "         7.43546244e-03, 2.60595009e-02, 6.53699739e-03],\n",
              "        [2.66731111e-03, 7.08069563e-01, 3.27819884e-02, ...,\n",
              "         1.03747156e-02, 2.06337851e-02, 6.90079946e-03],\n",
              "        ...,\n",
              "        [4.18205047e-03, 3.88470799e-01, 2.81545836e-02, ...,\n",
              "         2.51381435e-02, 2.25328598e-02, 1.93059202e-02],\n",
              "        [3.79845081e-03, 3.85819614e-01, 3.82578149e-02, ...,\n",
              "         3.31870690e-02, 3.11287511e-02, 2.38203518e-02],\n",
              "        [2.95704207e-03, 3.04262429e-01, 4.65065502e-02, ...,\n",
              "         4.09297645e-02, 4.09134589e-02, 2.05542240e-02]],\n",
              "\n",
              "       [[7.75449350e-03, 1.38216838e-01, 2.07056090e-01, ...,\n",
              "         2.34976429e-02, 7.01948404e-02, 2.10419800e-02],\n",
              "        [2.30865274e-03, 3.77080381e-01, 1.21458687e-01, ...,\n",
              "         1.21887689e-02, 5.22815101e-02, 9.90358926e-03],\n",
              "        [1.91275787e-03, 2.50170559e-01, 6.76792264e-02, ...,\n",
              "         2.82117911e-02, 6.19140454e-02, 8.62473063e-03],\n",
              "        ...,\n",
              "        [4.63541970e-03, 2.06619710e-01, 4.38113175e-02, ...,\n",
              "         3.01616043e-02, 3.40921171e-02, 1.86796188e-02],\n",
              "        [4.16108407e-03, 2.03646451e-01, 5.52146472e-02, ...,\n",
              "         4.26299013e-02, 4.53731231e-02, 2.27345377e-02],\n",
              "        [3.32521391e-03, 1.70746177e-01, 6.30172789e-02, ...,\n",
              "         5.04700430e-02, 5.37911281e-02, 1.97552182e-02]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[7.82418158e-03, 2.33829841e-01, 2.41517827e-01, ...,\n",
              "         1.99439675e-02, 1.00752994e-01, 1.26740234e-02],\n",
              "        [9.40851751e-04, 9.30937588e-01, 1.85212884e-02, ...,\n",
              "         2.63483892e-03, 6.37283409e-03, 3.01620900e-03],\n",
              "        [2.11610133e-03, 4.45354044e-01, 8.72623548e-02, ...,\n",
              "         1.75135005e-02, 7.07205981e-02, 1.14855468e-02],\n",
              "        ...,\n",
              "        [5.17112529e-03, 4.14473712e-01, 4.64889221e-02, ...,\n",
              "         2.78580580e-02, 4.00380343e-02, 1.97901297e-02],\n",
              "        [4.46533598e-03, 4.04455990e-01, 6.01423681e-02, ...,\n",
              "         4.09259461e-02, 4.98194881e-02, 2.56329775e-02],\n",
              "        [4.12154337e-03, 3.44092906e-01, 6.95727095e-02, ...,\n",
              "         4.66118678e-02, 6.01009727e-02, 2.45540310e-02]],\n",
              "\n",
              "       [[2.88833020e-04, 9.79647994e-01, 6.38513733e-03, ...,\n",
              "         1.67286466e-03, 1.85575383e-03, 1.98949082e-03],\n",
              "        [1.35418121e-03, 8.34444821e-01, 3.39191481e-02, ...,\n",
              "         7.40733696e-03, 2.05479600e-02, 5.80782350e-03],\n",
              "        [2.26860563e-03, 4.50083137e-01, 8.90977755e-02, ...,\n",
              "         1.97368748e-02, 7.51875490e-02, 1.21990861e-02],\n",
              "        ...,\n",
              "        [5.83199598e-03, 4.20365304e-01, 5.12314178e-02, ...,\n",
              "         2.94505227e-02, 4.34741974e-02, 2.14900263e-02],\n",
              "        [4.83020209e-03, 4.13594961e-01, 6.55734316e-02, ...,\n",
              "         4.40463722e-02, 5.31349555e-02, 2.75614019e-02],\n",
              "        [4.42585209e-03, 3.51519912e-01, 7.48021901e-02, ...,\n",
              "         4.93520387e-02, 6.41120076e-02, 2.45505348e-02]],\n",
              "\n",
              "       [[1.96859837e-04, 9.89183784e-01, 3.04098427e-03, ...,\n",
              "         1.47269433e-03, 2.58549087e-04, 1.25141768e-03],\n",
              "        [1.66864914e-03, 8.39382470e-01, 3.82861681e-02, ...,\n",
              "         7.26153422e-03, 1.53887784e-02, 5.49729168e-03],\n",
              "        [6.58472301e-04, 9.66784239e-01, 3.55590531e-03, ...,\n",
              "         1.63439859e-03, 4.05350327e-03, 1.37404527e-03],\n",
              "        ...,\n",
              "        [5.74182579e-03, 4.26281601e-01, 5.07011376e-02, ...,\n",
              "         2.94093899e-02, 4.22689803e-02, 2.09024157e-02],\n",
              "        [4.71115950e-03, 4.20526624e-01, 6.47501647e-02, ...,\n",
              "         4.43844311e-02, 5.17424308e-02, 2.70287562e-02],\n",
              "        [4.32842784e-03, 3.59503299e-01, 7.51679838e-02, ...,\n",
              "         4.87214327e-02, 6.30745962e-02, 2.39483546e-02]]], dtype=float32)"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformer.predict(test.batch(64))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40faUOENRbAa",
        "outputId": "7953cdce-89a1-43d0-8e57-230fd7d9b3fb"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Exception encountered when calling layer \"ner_model_7\" (type NERModel).\n\nnot enough values to unpack (expected 2, got 1)\n\nCall arguments received by layer \"ner_model_7\" (type NERModel):\n  • x=tf.Tensor(shape=(1, 100), dtype=int32)\n  • training=None",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_41196\\273627361.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mexample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'input_ids'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'word_ids'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_41196\\1224998812.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, x, training)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m# mask = x[:,seq_len:]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;31m# x = x[:,:seq_len]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"ner_model_7\" (type NERModel).\n\nnot enough values to unpack (expected 2, got 1)\n\nCall arguments received by layer \"ner_model_7\" (type NERModel):\n  • x=tf.Tensor(shape=(1, 100), dtype=int32)\n  • training=None"
          ]
        }
      ],
      "source": [
        "[np.argmax(x) for x in transformer(np.array([example['input_ids']]))[0]][:len(example['word_ids'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "xgkKbdM-XK96"
      },
      "outputs": [],
      "source": [
        "transformer.save_weights('model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2cc55bd8908>"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dummy = NERModel(\n",
        "    num_tags,\n",
        "    num_layers,\n",
        "    embedding_dim,\n",
        "    num_heads,\n",
        "    fully_connected_dim,\n",
        "    vocab_size,\n",
        "    positional_encoding_length,\n",
        "\n",
        ")\n",
        "dummy.load_weights('model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Unable to create a Keras model from SavedModel at model. This SavedModel was exported with `tf.saved_model.save`, and lacks the Keras metadata file. Please save your Keras model by calling `model.save`or `tf.keras.models.save_model`. Note that you can still load this SavedModel with `tf.saved_model.load`.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28452\\3495823505.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\saving\\saved_model\\load.py\u001b[0m in \u001b[0;36m_read_legacy_metadata\u001b[1;34m(object_graph_def, metadata, path)\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         raise ValueError(\n\u001b[1;32m--> 205\u001b[1;33m             \u001b[1;34mf'Unable to create a Keras model from SavedModel at {path}. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m             \u001b[1;34m'This SavedModel was exported with `tf.saved_model.save`, and '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m             \u001b[1;34m'lacks the Keras metadata file. Please save your Keras model by '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: Unable to create a Keras model from SavedModel at model. This SavedModel was exported with `tf.saved_model.save`, and lacks the Keras metadata file. Please save your Keras model by calling `model.save`or `tf.keras.models.save_model`. Note that you can still load this SavedModel with `tf.saved_model.load`."
          ]
        }
      ],
      "source": [
        "tf.keras.models.load_model('model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgbMoIwfjdWN",
        "outputId": "fe86be7c-ff17-4144-eebb-a5376c74c65d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[np.argmax(x) for x in dummy(np.array([example['input_ids']]))[0]][:len(example['word_ids'])]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
